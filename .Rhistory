# Función para convertir un nucleótido a one-hot encoding
one_hot_encode_nucleotido <- function(nucleotido) {
# Convertimos siempre a mayúsculas
nucleotido.upper <- toupper(nucleotido)
switch(nucleotido.upper,
"A" = c(0, 0, 0, 1),
"C" = c(0, 0, 1, 0),
"G" = c(0, 1, 0, 0),
"T" = c(1, 0, 0, 0),
rep(0, 4)) # Devuelve un vector de ceros si el nucleótido se reconoce
}
# Función para convertir toda una secuencia a one-hot encoding
one_hot_encode_seq <- function(seq) {
# Separamos la secuencia
split.seq <- strsplit(seq, "")[[1]]
# Generamos la matriz one_hot con la secuencia
matrix.seq <- sapply(split.seq, one_hot_encode_nucleotido)
# Con todas las columnas de la matriz generamos un único vector one-hot
vector.unico <- c(matrix.seq)
# Devolvemos el vector con toda la secuencia one-hot
vector.unico
}
# Cargamos el archivo promoters.txt en un DataFrame
promoters_df <- read.table(data, header = FALSE, sep = ",")
# Obtenemos el número de filas y columnas
dimensiones <- dim(promoters_df)
filas <- dimensiones[1]
columnas <- dimensiones[2]
# Extraemos las dos primeras columnas "class" y "names"; las utilizaremos más adelante.
class_names_columnas <- promoters_df[, 1:2]
# Cogemos las secuencias de la 3a columna y las convertimos a one-hot
one_hot_encoded_sequences <- lapply(promoters_df[[3]], one_hot_encode_seq)
# Convertimos los resultados en una matriz de codificación one-hot
one_hot_encoded_matrix <- do.call(rbind, one_hot_encoded_sequences)
# Añadimos las columnas extraídas con la matriz de codificación one-hot
promoters_one.hot_df <- cbind(class_names_columnas, one_hot_encoded_matrix)
# Añadimos nombres a las dos primeras clumnas
names(promoters_one.hot_df)[1:2] <- c("class", "names")
# Convertimos la columna "class" en factor
promoters_one.hot_df$class <- factor(promoters_one.hot_df$class)
# Separamos la base de datos en dos grupos: el grupo data.train con el 67 % de
# las observaciones (params$p.train) y el grupo data.test con el resto
# Fijamos la semilla para que los cálculos pseudo-aleatorios sean reproducibles
set.seed(params$seed)
# Obtenemos el número total de filas (datos) de parkinson
n <- nrow(promoters_one.hot_df)
# Calculamos el número de filas para entrenamiento y pruebas
n_train <- round(params$p.train * n) # 67%
n_test <- n - n_train # 33%
# Obtenemos los índices de filas al azar para entrenamiento
indices_train <- sample(1:n, n_train)
# Seleccionamos las filas para entrenamiento
data.train <- promoters_one.hot_df[indices_train,]
# Eliminamos la segunda columna "names"
data.train <- data.train[, -2]
# Seleccionamos las filas restantes para pruebas
data.test <- promoters_one.hot_df[-indices_train, ]
# Eliminamos la segunda columna "names"
data.test <- data.test[, -2]
View(data.test)
View(data.train)
require(kernlab)
# Hacemos el clasificador de promotores con el modelo lineal ksvm.
mod_ksvm_lineal <- ksvm(class ~ ., data = data.train, kernel = "vanilladot", C = 1)
# Vemos la información del modelo
mod_ksvm_lineal
# Predicción del test con el kernel lineal
pred_ksvm_lineal <- predict(mod_ksvm_lineal, data.test)
# Métricas de rendimiento
require(caret)
# Matriz de confusión
res <- table(pred_ksvm_lineal, data.test$class)
conf.mat.ksvm.lineal <- confusionMatrix(res, positive="+")
# Visualizamos
conf.mat.ksvm.lineal
#require(kernlab)
# Hacemos el clasificador de promotores con el modelo lineal ksvm.
mod_ksvm_RBF <- ksvm(class ~ ., data = data.train, kernel = "rbfdot", C = 1)
# Vemos la información del modelo
mod_ksvm_RBF
# Predicción del test con el kernel RBF
pred_ksvm_RBF <- predict(mod_ksvm_RBF, data.test)
# Métricas de rendimiento
# require(caret)
# Matriz de confusión
res <- table(pred_ksvm_RBF, data.test$class)
conf.mat.ksvm.RBF <- confusionMatrix(res, positive="+")
# Visualizamos
conf.mat.ksvm.RBF
# Hacemos el clasificador de promotores con el modelo lineal ksvm.
mod_svmLinear <- train(class ~ ., data.train, method='svmLinear',
trControl= trainControl(method='none'),
# preProcess = "range",
tuneGrid= NULL, trace = FALSE)
# Vemos la información del modelo
mod_svmLinear
# Hacemos el clasificador de promotores con el modelo lineal ksvm.
mod_svmLinear <- train(class ~ ., data.train, method='svmLinear',
trControl= trainControl(method='none'),
# preProcess = "range",
tuneGrid= NULL, trace = FALSE)
# Vemos la información del modelo
mod_svmLinear
# Predicción del test con el kernel RBF
pred_svmLinear <- predict(mod_svmLinear, data.test)
# Métricas de rendimiento
# require(caret)
# Matriz de confusión
res <- table(pred_svmLinear, data.test$class)
conf.mat.svmLinear <- confusionMatrix(res, positive="+")
# Visualizamos
conf.mat.svmLinear
# Hacemos el clasificador de promotores con el modelo lineal ksvm.
mod_svmLinear <- train(class ~ ., data.train, method='svmLinear',
trControl= trainControl(method='none'),
# preProcess = "range",
tuneGrid= NULL, trace = FALSE)
# Vemos la información del modelo
mod_svmLinear
# Bibliografía
# Requerimos la librería bibtext
require(bibtex)
# Cargamos los datos del fichero .bib conseguido mediante google scholar
bib_file <- params$bibliography
# Leemos los datos del fichero .bib
bib_data <- read.bib(bib_file)
# Bibliografía
# Requerimos la librería bibtext
require(bibtex)
# Cargamos los datos del fichero .bib conseguido mediante google scholar
bib_file <- "PEC_3_ML.bib"
# Leemos los datos del fichero .bib
bib_data <- read.bib(bib_file)
# Mostramos el resultado
bib_data
# Configurar el control de entrenamiento para la validación cruzada
train_control <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
# Definir la grilla de hiperparámetros
grid <- expand.grid(sigma = seq(0.005, 0.5, length = 10),
C = seq(0.1, 2, length = 10))
# Entrenar el modelo SVM con kernel RBF
svm_model <- train(class ~ ., data = data.train, method = "svmRadial",
trControl = train_control, tuneGrid = grid)
# Entrenar el modelo SVM con kernel RBF
svm_model <- train(class ~ ., data = data.train, method = "svmRadial",
trControl = train_control, tuneGrid = grid)
# Graficar los resultados
plot(svm_model)
train_control <- trainControl(method = "cv", number = 5, repeats = 0)
# Definir la grilla de hiperparámetros
grid <- expand.grid(sigma = seq(0.005, 0.5, length = 5),
C = seq(0.1, 2, length = 5))
# Entrenar el modelo SVM con kernel RBF
svm_model <- train(class ~ ., data = data.train, method = "svmRadial",
trControl = train_control, tuneGrid = grid)
# Graficar los resultados
plot(svm_model)
# Entrenar el modelo SVM con kernel RBF
svm_model <- train(class ~ ., data = data.train, method = "svmRadial",
tuneGrid = grid)
# Entrenar el modelo SVM con kernel RBF
svm_model <- train(class ~ ., data = data.train, method = "svmRadial",
tuneGrid = grid)
# Graficar los resultados
plot(svm_model)
# Suponiendo que svm_model es el modelo entrenado con caret
resultados <- svm_model$results
# Ordenar los resultados por alguna métrica, por ejemplo, Accuracy
resultados_ordenados <- resultados[order(-resultados$Accuracy),]
# Crear una tabla resumen
tabla_resumen <- resultados_ordenados[, c("sigma", "C", "Accuracy", "Kappa", ...otros)]
View(resultados_ordenados)
# Crear una tabla resumen
tabla_resumen <- resultados_ordenados[, c("sigma", "C", "Accuracy", "Kappa")]
View(tabla_resumen)
View(resultados)
resultados
mod_ksvm_lineal$results
View(mod_ksvm_lineal)
# ksvm.lineal
conf.mat.ksvm.lineal$overall["Accuracy"]
conf.mat.ksvm.lineal$overall["Kappa"]
# ksvm.RBF
conf.mat.ksvm.RBF$overall["Accuracy"]
conf.mat.ksvm.RBF$overall["Kappa"]
# Caret svmLiear
mod_svmLinear$results
# Suponiendo que svm_model es el modelo entrenado con caret
resultados <- svm_model$results
resultados
# Caret svmLiear
conf.mat.svmLinear$overall["Accuracy"]
conf.mat.svmLinear$overall["Kappa"]
conf.mat.3fold.cross$overall["Accuracy"]
# Hacemos el clasificador de promotores con el modelo lineal ksvm.
mod_ksvm_lineal <- ksvm(class ~ ., data = data.train, kernel = "vanilladot", C = 2)
# Vemos la información del modelo
mod_ksvm_lineal
# Predicción del test con el kernel lineal
pred_ksvm_lineal <- predict(mod_ksvm_lineal, data.test)
# Métricas de rendimiento
require(caret)
# Matriz de confusión
res <- table(pred_ksvm_lineal, data.test$class)
conf.mat.ksvm.lineal <- confusionMatrix(res, positive="+")
# Visualizamos
conf.mat.ksvm.lineal
View(resultados)
# Hacemos el clasificador de promotores con el modelo lineal ksvm del paquete "caret".
# Train sin repetición
tunegrid <- NULL
mod_svmLinear <- train(class ~ ., data.train, method='svmLinear',
trControl= trainControl(method='none'),
tuneGrid = tunegrid, trace = FALSE)
# Vemos la información del modelo
mod_svmLinear
# Métricas de rendimiento
# require(caret)
# Matriz de confusión
res <- table(pred_svmLinear, data.test$class)
conf.mat.svmLinear <- confusionMatrix(res, positive="+")
# Visualizamos
conf.mat.svmLinear
# Hacemos el clasificador de promotores con 3-fold crossvalidation del paquete "caret".
#tune_grid <- NULL
tune_grid <- expand.grid(C = 2)
mod_3fold_cross <- train(class ~ ., data.train, method='svmLinear',
trControl= trainControl(method='cv', number=3),
tuneGrid= tune_grid, trace = FALSE)
# Vemos la información del modelo
mod_3fold_cross
# Hacemos el clasificador de promotores con 3-fold crossvalidation del paquete "caret".
tune_grid <- NULL
#tune_grid <- expand.grid(C = 2)
mod_3fold_cross <- train(class ~ ., data.train, method='svmLinear',
trControl= trainControl(method='cv', number=3),
tuneGrid= tune_grid, trace = FALSE)
# Vemos la información del modelo
mod_3fold_cross
# Hacemos el clasificador de promotores con 3-fold crossvalidation del paquete "caret".
#tune_grid <- NULL
tune_grid <- expand.grid(C = 2)
mod_3fold_cross <- train(class ~ ., data.train, method='svmLinear',
trControl= trainControl(method='cv', number=3),
tuneGrid= tune_grid, trace = FALSE)
# Vemos la información del modelo
mod_3fold_cross
# Hacemos el clasificador de promotores con 3-fold crossvalidation del paquete "caret".
#tune_grid <- NULL
tune_grid <- expand.grid(C = 1.5)
mod_3fold_cross <- train(class ~ ., data.train, method='svmLinear',
trControl= trainControl(method='cv', number=3),
tuneGrid= tune_grid, trace = FALSE)
# Vemos la información del modelo
mod_3fold_cross
# Hacemos el clasificador de promotores con 3-fold crossvalidation del paquete "caret".
#tune_grid <- NULL
tune_grid <- expand.grid(C = 2)
mod_3fold_cross <- train(class ~ ., data.train, method='svmLinear',
trControl= trainControl(method='cv', number=3),
tuneGrid= tune_grid, trace = FALSE)
# Vemos la información del modelo
mod_3fold_cross
# Hacemos el clasificador de promotores con el modelo lineal ksvm del paquete "caret".
# Train sin repetición
#tunegrid <- NULL
tune_grid <- expand.grid(C = 1.5)
mod_svmLinear <- train(class ~ ., data.train, method='svmLinear',
trControl= trainControl(method='none'),
tuneGrid = tunegrid, trace = FALSE)
# Vemos la información del modelo
mod_svmLinear
# Hacemos el clasificador de promotores con 3-fold crossvalidation del paquete "caret".
#tune_grid <- NULL
tune_grid <- expand.grid(C = 1.5)
mod_3fold_cross <- train(class ~ ., data.train, method='svmLinear',
trControl= trainControl(method='cv', number=3),
tuneGrid= tune_grid, trace = FALSE)
# Vemos la información del modelo
mod_3fold_cross
# Hacemos el clasificador de promotores con el modelo lineal ksvm del paquete "caret".
# Train sin repetición
#tunegrid <- NULL
tune_grid <- expand.grid(C = 1.5)
mod_svmLinear <- train(class ~ ., data.train, method='svmLinear',
trControl= trainControl(method='none'),
tuneGrid = tunegrid, trace = FALSE)
# Vemos la información del modelo
mod_svmLinear
# Predicción del test con kernel lineal del paquete `caret`
pred_svmLinear <- predict(mod_svmLinear, data.test)
# Métricas de rendimiento
# require(caret)
# Matriz de confusión
res <- table(pred_svmLinear, data.test$class)
conf.mat.svmLinear <- confusionMatrix(res, positive="+")
# Visualizamos
conf.mat.svmLinear
# Hacemos el clasificador de promotores con el modelo lineal ksvm del paquete "caret".
# Train sin repetición
tunegrid <- NULL
#tune_grid <- expand.grid(C = 1.5)
mod_svmLinear <- train(class ~ ., data.train, method='svmLinear',
trControl= trainControl(method='none'),
tuneGrid = tunegrid, trace = FALSE)
# Vemos la información del modelo
mod_svmLinear
# Predicción del test con kernel lineal del paquete `caret`
pred_svmLinear <- predict(mod_svmLinear, data.test)
# Métricas de rendimiento
# require(caret)
# Matriz de confusión
res <- table(pred_svmLinear, data.test$class)
conf.mat.svmLinear <- confusionMatrix(res, positive="+")
# Visualizamos
conf.mat.svmLinear
# Hacemos el clasificador de promotores con el modelo lineal ksvm del paquete "caret".
# Train sin repetición
#tunegrid <- NULL
tune_grid <- expand.grid(C = 1.5)
mod_svmLinear <- train(class ~ ., data.train, method='svmLinear',
trControl= trainControl(method='none'),
tuneGrid = tunegrid, trace = FALSE)
# Vemos la información del modelo
mod_svmLinear
# Predicción del test con kernel lineal del paquete `caret`
pred_svmLinear <- predict(mod_svmLinear, data.test)
# Métricas de rendimiento
# require(caret)
# Matriz de confusión
res <- table(pred_svmLinear, data.test$class)
conf.mat.svmLinear <- confusionMatrix(res, positive="+")
# Visualizamos
conf.mat.svmLinear
# Hacemos el clasificador de promotores con 3-fold crossvalidation del paquete "caret".
#tune_grid <- NULL
tune_grid <- expand.grid(C = 1.5)
mod_3fold_cross <- train(class ~ ., data.train, method='svmLinear',
trControl= trainControl(method='cv', number=3),
tuneGrid= tune_grid, trace = FALSE)
# Vemos la información del modelo
mod_3fold_cross
# Hacemos el clasificador de promotores con 3-fold crossvalidation del paquete "caret".
tune_grid <- NULL
#tune_grid <- expand.grid(C = 1.5)
mod_3fold_cross <- train(class ~ ., data.train, method='svmLinear',
trControl= trainControl(method='cv', number=3),
tuneGrid= tune_grid, trace = FALSE)
# Vemos la información del modelo
mod_3fold_cross
# Hacemos el clasificador de promotores con 3-fold crossvalidation del paquete "caret".
#tune_grid <- NULL
tune_grid <- expand.grid(C = 1.5)
mod_3fold_cross <- train(class ~ ., data.train, method='svmLinear',
trControl= trainControl(method='cv', number=3),
tuneGrid= tune_grid, trace = FALSE)
# Vemos la información del modelo
mod_3fold_cross
# Hacemos el clasificador de promotores con el modelo lineal ksvm del paquete "caret".
# Train sin repetición
#tunegrid <- NULL
tune_grid <- expand.grid(C = 1.5)
mod_svmLinear <- train(class ~ ., data.train, method='svmLinear',
trControl= trainControl(method='none'),
tuneGrid = tunegrid, trace = FALSE)
# Vemos la información del modelo
mod_svmLinear
# Predicción del test con kernel lineal del paquete `caret`
pred_svmLinear <- predict(mod_svmLinear, data.test)
# Métricas de rendimiento
# require(caret)
# Matriz de confusión
res <- table(pred_svmLinear, data.test$class)
conf.mat.svmLinear <- confusionMatrix(res, positive="+")
# Visualizamos
conf.mat.svmLinear
# Hacemos el clasificador de promotores con 3-fold crossvalidation del paquete "caret".
#tune_grid <- NULL
tune_grid <- expand.grid(C = 2)
mod_3fold_cross <- train(class ~ ., data.train, method='svmLinear',
trControl= trainControl(method='cv', number=3),
tuneGrid= tune_grid, trace = FALSE)
# Vemos la información del modelo
mod_3fold_cross
# Predicción del test con 3-fold crossvalidation
pred_3fold_cross <- predict(mod_3fold_cross, data.test)
# Métricas de rendimiento
# require(caret)
# Matriz de confusión
res <- table(pred_3fold_cross, data.test$class)
conf.mat.3fold.cross <- confusionMatrix(res, positive="+")
# Visualizamos
conf.mat.3fold.cross
require(kernlab)
# Hacemos el clasificador de promotores con el modelo lineal ksvm.
mod_ksvm_lineal <- ksvm(class ~ ., data = data.train, kernel = "vanilladot", C = 1.5)
# Vemos la información del modelo
mod_ksvm_lineal
# Predicción del test con el kernel lineal
pred_ksvm_lineal <- predict(mod_ksvm_lineal, data.test)
# Métricas de rendimiento
require(caret)
# Matriz de confusión
res <- table(pred_ksvm_lineal, data.test$class)
conf.mat.ksvm.lineal <- confusionMatrix(res, positive="+")
# Visualizamos
conf.mat.ksvm.lineal
# Hacemos el clasificador de promotores con el modelo lineal ksvm del paquete "caret".
# Train sin repetición
#tunegrid <- NULL
tune_grid <- expand.grid(C = 1)
mod_svmLinear <- train(class ~ ., data.train, method='svmLinear',
trControl= trainControl(method='none'),
tuneGrid = tune_grid, trace = FALSE)
# Vemos la información del modelo
mod_svmLinear
# Predicción del test con kernel lineal del paquete `caret`
pred_svmLinear <- predict(mod_svmLinear, data.test)
# Métricas de rendimiento
# require(caret)
# Matriz de confusión
res <- table(pred_svmLinear, data.test$class)
conf.mat.svmLinear <- confusionMatrix(res, positive="+")
# Visualizamos
conf.mat.svmLinear
# Hacemos el clasificador de promotores con 3-fold crossvalidation del paquete "caret".
#tune_grid <- NULL
tune_grid <- expand.grid(C = 1.5)
mod_3fold_cross <- train(class ~ ., data.train, method='svmLinear',
trControl= trainControl(method='cv', number=3),
tuneGrid= tune_grid, trace = FALSE)
# Vemos la información del modelo
mod_3fold_cross
# Hacemos el clasificador de promotores con 3-fold crossvalidation del paquete "caret".
#tune_grid <- NULL
tune_grid <- expand.grid(C = 1.5)
mod_3fold_cross <- train(class ~ ., data.train, method='svmLinear',
trControl= trainControl(method='cv', number=3),
tuneGrid= tune_grid, trace = FALSE)
# Vemos la información del modelo
mod_3fold_cross
# Predicción del test con 3-fold crossvalidation
pred_3fold_cross <- predict(mod_3fold_cross, data.test)
# Métricas de rendimiento
# require(caret)
# Matriz de confusión
res <- table(pred_3fold_cross, data.test$class)
conf.mat.3fold.cross <- confusionMatrix(res, positive="+")
# Visualizamos
conf.mat.3fold.cross
#library(caret)
#Partición de datos
set.seed(params$seed)
# We wish 75% for the trainset
inTrain <- createDataPartition(y=dataset$class, p=params$p.train, list=FALSE)
#library(caret)
#Partición de datos
set.seed(params$seed)
# We wish 75% for the trainset
inTrain <- createDataPartition(y=data$class, p=params$p.train, list=FALSE)
# We wish 75% for the trainset
indices_train.caret <- createDataPartition(y=promoters_one.hot_df$class, p=params$p.train, list=FALSE)
#library(caret)
#Partición de datos
set.seed(params$seed)
# Seleccionamos el % con p.train de los parámetros (2/3)
indices_train.caret <- createDataPartition(y=promoters_one.hot_df$class,
p=params$p.train, list=FALSE)
# Creamos los dos sets
data.train.caret <- dataset[indices_train.caret,]
# Eliminamos la segunda columna "names"
data.train.caret <- data.train.caret[, -2]
# Creamos los dos sets
data.train.caret <- dataset[indices_train.caret,]
# Creamos los dos sets
data.train.caret <- promoters_one.hot_df[indices_train.caret,]
# Eliminamos la segunda columna "names"
data.train.caret <- data.train.caret[, -2]
# Seleccionamos las filas restantes para pruebas
data.test.caret  <- promoters_one.hot_df[-indices_train.caret,]
# Eliminamos la segunda columna "names"
data.test.caret <- data.test.caret[, -2]
nrow(data.train.caret)/nrow(data.test.caret) # should be around 2 if train=2/3
View(data.train.caret)
View(data.train)
View(data.train)
View(data.train.caret)
# Creamos los dos sets
data.train.caret <- promoters_one.hot_df[indices_train.caret,]
# Eliminamos la segunda columna "names"
data.train.caret <- data.train.caret[, -2]
# Seleccionamos las filas restantes para pruebas
data.test.caret  <- promoters_one.hot_df[-indices_train.caret,]
# Eliminamos la segunda columna "names"
data.test.caret <- data.test.caret[, -2]
conf.mat.ksvm.lineal$overall["Specificity"]
conf.mat.3fold.cross$overall["Kappa"]
# 2. Creamos el histograma con ggplot2
pl <- ggplot(data = svm_model$results, aes(x = Length))
# Cargar la librería ggplot2
library(ggplot2)
# 2. Creamos el histograma con ggplot2
pl <- ggplot(data = svm_model$results, aes(x = Length))
pl2
pl
# 2. Creamos el histograma con ggplot2
pl <- ggplot(data = svm_model$results)
pl
# 2. Creamos el histograma con ggplot2
pl <- ggplot(data = svm_model)
pl
if(!(require(ggplot2))) install.packages("ggplot2")
